# -*- coding: utf-8 -*-
"""KITTI_object_detection_YOLOv8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17iSyDnrmZhe9X9As2qMIaSn3OxmUXFDn
"""

# Step 1: Install the necessary library
!pip install ultralytics
!pip install opencv-python
!pip install pandas

# Step 2: Import the required libraries
import torch
from ultralytics import YOLO
import cv2
import os
import time
import numpy as np
import pandas as pd
from google.colab import drive
from sklearn.metrics import f1_score, precision_score, recall_score

# Step 3: Mount Google Drive
drive.mount('/content/drive')

# Step 4: Define paths
input_folder = '/content/drive/MyDrive/OD/input'  # Change to your input folder path
output_folder = '/content/drive/MyDrive/OD/output'  # Change to your output folder path
metrics_path = '/content/drive/MyDrive/OD/metrics_results.csv'

# Create output folder if it doesn't exist
os.makedirs(output_folder, exist_ok=True)

# Step 5: Load the YOLOv8 model
model = YOLO('yolov8n.pt')  # Load the YOLOv8 model

# Metrics initialization
true_positives = 0
false_positives = 0
false_negatives = 0
total_detections = 0
latencies = []

# Step 6: Process each image in the input folder
for image_name in os.listdir(input_folder):
    image_path = os.path.join(input_folder, image_name)

    # Load the image
    img = cv2.imread(image_path)

    # Start time for latency measurement
    start_time = time.time()

    # Run inference
    results = model(img)

    # End time for latency measurement
    end_time = time.time()
    latencies.append(end_time - start_time)

    # Display results (only for cars)
    detected_boxes = []
    for result in results:
        boxes = result.boxes.xyxy  # Bounding box coordinates
        scores = result.boxes.conf  # Confidence scores
        cls_ids = result.boxes.cls   # Class IDs

        # Filter for cars (class ID 2)
        for box, score, cls_id in zip(boxes, scores, cls_ids):
            if int(cls_id) == 2:  # Only consider the 'car' class
                x1, y1, x2, y2 = map(int, box)
                detected_boxes.append((x1, y1, x2, y2, score))

                # Draw bounding boxes on the image
                label = f'{model.names[int(cls_id)]} {score:.2f}'
                cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
                cv2.putText(img, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

    # Save the output image
    output_image_path = os.path.join(output_folder, image_name)
    cv2.imwrite(output_image_path, img)

    # Here you would calculate true positives, false positives, etc.
    # For simplicity, we'll simulate these metrics for demonstration
    # You need actual ground truth data to compute these metrics correctly
    # This part needs your ground truth annotations for accurate calculations

# Step 7: Calculate metrics
# Assume you have ground truth annotations for the images
# You would calculate these based on actual data
# For the purpose of this example, let's simulate values
true_positives = 100  # Replace with actual calculation
false_positives = 20   # Replace with actual calculation
false_negatives = 10   # Replace with actual calculation

precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0
recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0
f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
mean_ap = (precision + recall) / 2  # Simulated; you should calculate actual mAP

# Speed and latency
avg_latency = np.mean(latencies)
fps = 1 / avg_latency if avg_latency > 0 else 0

# Step 8: Save metrics to a CSV file
metrics_data = {
    'F1 Score': [f1],
    'Mean Average Precision': [mean_ap],
    'True Positives': [true_positives],
    'False Positives': [false_positives],
    'False Negatives': [false_negatives],
    'Average Latency (s)': [avg_latency],
    'Frames Per Second (FPS)': [fps]
}

metrics_df = pd.DataFrame(metrics_data)
metrics_df.to_csv(metrics_path, index=False)

# Print metrics
print(metrics_df)

